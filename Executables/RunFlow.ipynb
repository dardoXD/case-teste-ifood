{"cells":[{"cell_type":"markdown","source":["# Arquivo de Execução dos Fluxos\n\n* Argumentos:\n  * flow: Nome do Flow igual ao da classe criada com as regras"],"metadata":{}},{"cell_type":"markdown","source":["Criação dos widgets que receberão os argumentos"],"metadata":{}},{"cell_type":"code","source":["dbutils.widgets.text(\"flow\", \"\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["Importação do arquivo com as classes dos Fluxos criadas"],"metadata":{}},{"cell_type":"code","source":["%run ./RequirementsFlows"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["* Atribuição dos valores dos argumentos às variáveis\n* Execução da classe correspondente ao fluxo"],"metadata":{}},{"cell_type":"code","source":["flow = dbutils.widgets.get(\"flow\")\nflowExec = eval(f'Flow{flow}(\\'{flow}\\')')\nresult = flowExec.run()\ndisplay(result)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-366638425735896&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> flow <span class=\"ansi-blue-fg\">=</span> dbutils<span class=\"ansi-blue-fg\">.</span>widgets<span class=\"ansi-blue-fg\">.</span>get<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;flow&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>flowExec <span class=\"ansi-blue-fg\">=</span> eval<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#39;Flow{flow}(\\&#39;{flow}\\&#39;)&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> result <span class=\"ansi-blue-fg\">=</span> flowExec<span class=\"ansi-blue-fg\">.</span>run<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> display<span class=\"ansi-blue-fg\">(</span>result<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;string&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n\n<span class=\"ansi-green-fg\">&lt;command-4001667649767250&gt;</span> in <span class=\"ansi-cyan-fg\">__init__</span><span class=\"ansi-blue-fg\">(self, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      9</span>         self<span class=\"ansi-blue-fg\">.</span>name <span class=\"ansi-blue-fg\">=</span> name\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span> \n<span class=\"ansi-green-fg\">---&gt; 11</span><span class=\"ansi-red-fg\">         </span>df <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>run<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     12</span>         self<span class=\"ansi-blue-fg\">.</span>writeFlowResult<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span> \n\n<span class=\"ansi-green-fg\">&lt;command-3104674543945716&gt;</span> in <span class=\"ansi-cyan-fg\">run</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>         df_final <span class=\"ansi-blue-fg\">=</span> orderDF<span class=\"ansi-blue-fg\">.</span>join<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">,</span> orderDF<span class=\"ansi-blue-fg\">.</span>order_id <span class=\"ansi-blue-fg\">==</span> df<span class=\"ansi-blue-fg\">.</span>order_id<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     66</span> \n<span class=\"ansi-green-fg\">---&gt; 67</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">if</span> FlowBase<span class=\"ansi-blue-fg\">.</span>checkDuplicates<span class=\"ansi-blue-fg\">(</span>df_final<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>             dbutils<span class=\"ansi-blue-fg\">.</span>notebook<span class=\"ansi-blue-fg\">.</span>exit<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;ERROR: Existem linhas duplicadas&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     69</span> \n\n<span class=\"ansi-green-fg\">&lt;command-4001667649767250&gt;</span> in <span class=\"ansi-cyan-fg\">checkDuplicates</span><span class=\"ansi-blue-fg\">(df)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     25</span>     <span class=\"ansi-blue-fg\">@</span>staticmethod\n<span class=\"ansi-green-intense-fg ansi-bold\">     26</span>     <span class=\"ansi-green-fg\">def</span> checkDuplicates<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 27</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">if</span> df<span class=\"ansi-blue-fg\">.</span>count<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> df<span class=\"ansi-blue-fg\">.</span>dropDuplicates<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">.</span>schema<span class=\"ansi-blue-fg\">.</span>names<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>count<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span>             <span class=\"ansi-green-fg\">return</span> <span class=\"ansi-green-fg\">True</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">count</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    584</span>         <span class=\"ansi-cyan-fg\">2</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    585</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 586</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> int<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>count<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    587</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    588</span>     <span class=\"ansi-blue-fg\">@</span>ignore_unicode_prefix\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    126</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    127</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 128</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    130</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o12589.count.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 1442.0 failed 4 times, most recent failure: Lost task 5.3 in stage 1442.0 (TID 33696, 10.68.234.186, executor 46): ExecutorLostFailure (executor 46 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2476)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2425)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2424)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2424)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1129)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1129)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1129)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2676)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2623)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2611)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:915)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2313)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2408)\n\tat org.apache.spark.sql.execution.collect.Collector.runSparkJobs(Collector.scala:273)\n\tat org.apache.spark.sql.execution.collect.Collector.collect(Collector.scala:308)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:82)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:88)\n\tat org.apache.spark.sql.execution.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:508)\n\tat org.apache.spark.sql.execution.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:480)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollectResult(SparkPlan.scala:396)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:372)\n\tat org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3020)\n\tat org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3019)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3684)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:248)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:835)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:198)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3682)\n\tat org.apache.spark.sql.Dataset.count(Dataset.scala:3019)\n\tat sun.reflect.GeneratedMethodAccessor467.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>"]}}],"execution_count":7}],"metadata":{"name":"RunFlow","notebookId":366638425735894},"nbformat":4,"nbformat_minor":0}
